{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datasets\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.modeling_outputs import CausalLMOutputWithPast\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/envs/py3.11_pt2_cu11.8/lib/python3.11/site-packages/datasets/load.py:1486: FutureWarning: The repository for deepmind/pg19 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/deepmind/pg19\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ds = datasets.load_dataset('deepmind/pg19')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:40<00:00,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Let us stay here,' she exclaimed. 'The one room is as good as the other for what we have to talk ab\n",
      "Number of words in the sample: 14391\n",
      "----------\n",
      "These lobsters don't realize that Jonesy's fast one would pass right through a batter without pausin\n",
      "Number of words in the sample: 16530\n",
      "----------\n",
      "It certainly was not relief that he felt on discovering that she was paying no attention whatever to\n",
      "Number of words in the sample: 15784\n",
      "----------\n",
      "Down to 1765 the duty imposed was only one penny, but as newspapers grew in influence the restrainin\n",
      "Number of words in the sample: 14113\n",
      "----------\n",
      "And what was, perhaps, more extraordinary, though interrupted in the progress of his calculations, a\n",
      "Number of words in the sample: 14564\n",
      "----------\n",
      "Oh, remember prayer is the great means of spiritual improvement, and guard as you would against a wi\n",
      "Number of words in the sample: 20424\n",
      "----------\n",
      "Bonaparte could not well afford another direct attack, with its attendant losses, and strove to turn\n",
      "Number of words in the sample: 19584\n",
      "----------\n",
      "I must confess, I thought of nothing. And let that encourage the next bride, who will imagine hersel\n",
      "Number of words in the sample: 15266\n",
      "----------\n",
      "THAT WE SHOULD NOT BE TOO SOLICITOUS FOR ACTUAL AND SENSIBLE DEVOTION, BUT DESIRE RATHER THE UNION O\n",
      "Number of words in the sample: 12705\n",
      "----------\n",
      "came in muffled tones from the first mask, and \"Death!\" echoed the next, and the next, until all had\n",
      "Number of words in the sample: 15913\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from nltk import sent_tokenize\n",
    "# random.seed(144)\n",
    "\n",
    "# Function to get a random chunk from a text with a minimum chunk size\n",
    "def get_random_chunk(text, min_chunk_size):\n",
    "    text = ' '.join(text.split())\n",
    "    sentences = sent_tokenize(text)\n",
    "    if len(sentences) < min_chunk_size:\n",
    "        return ' '.join(sentences)  # Return the entire text if it's shorter than min_chunk_size\n",
    "    n_words = 0\n",
    "    while not (n_words < 25000 and n_words > 12000):\n",
    "        max_start = len(sentences) - min_chunk_size\n",
    "        start = random.randint(0, max_start)\n",
    "        end = random.randint(start + min_chunk_size, len(sentences))\n",
    "        chunk = ' '.join(sentences[start:end])\n",
    "        n_words = len(chunk.split())\n",
    "    return chunk\n",
    "\n",
    "# Sample 10 random chunks from texts\n",
    "texts = []\n",
    "min_chunk_size = 10  # Set the minimum chunk size (in sentences)\n",
    "for _ in tqdm(range(1000)):\n",
    "    # Choose a random text from the validation set\n",
    "    n_words = 0\n",
    "    while n_words < 12000:\n",
    "        text = random.choice(ds['validation'])['text']\n",
    "        n_words = len(text.split())\n",
    "    # Get a random chunk from this text with the minimum size\n",
    "    chunk = get_random_chunk(text, min_chunk_size)\n",
    "    texts.append(chunk)\n",
    "\n",
    "for t in texts[:10]:\n",
    "    print(t[:100])    \n",
    "    print(f\"Number of words in the sample: {len(t.split())}\")\n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'Let us stay here,' she exclaimed. 'The one ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>These lobsters don't realize that Jonesy's fas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It certainly was not relief that he felt on di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Down to 1765 the duty imposed was only one pen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And what was, perhaps, more extraordinary, tho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  'Let us stay here,' she exclaimed. 'The one ro...\n",
       "1  These lobsters don't realize that Jonesy's fas...\n",
       "2  It certainly was not relief that he felt on di...\n",
       "3  Down to 1765 the duty imposed was only one pen...\n",
       "4  And what was, perhaps, more extraordinary, tho..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'text': texts})\n",
    "df.to_csv('pg19_valid_1k_chunks.csv')\n",
    "\n",
    "df = pd.read_csv('pg19_valid_1k_chunks.csv', index_col=0)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
